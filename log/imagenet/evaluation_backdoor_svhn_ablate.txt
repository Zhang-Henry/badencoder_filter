2024-02-02 16:58:27.655547: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-02 16:58:28.497682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
当前时间： 2024-02-02 16:58:34
当前时间： 2024-02-02 16:58:35
test_transform_imagenet
Loaded from: output/imagenet/svhn_backdoored_encoder/2023-12-25-10:10:35/model_50.pth
Namespace(batch_size=32, color=0.0, data_dir='./data/imagenet/', encoder_usage_info='imagenet', epochs=200, gpu='0', hue_hsv=1, knn_k=200, knn_t=0.5, lambda1=1.0, lambda2=1.0, lightness=1, loss0=20.0, lr=0.001, pretrained_encoder='./output/imagenet/clean_encoder/resnet50-1x.pth', pretraining_dataset='imagenet', psnr=0.025, rand_init=False, reference_file='./reference/imagenet/one.npz', reference_label=0, results_dir='./output/imagenet/svhn_backdoored_encoder/2023-12-25-10:10:35/', saturation_hsv=1, seed=100, shadow_dataset='imagenet', timestamp='2023-12-25-10:10:35', trigger_file='optimize_filter/trigger/imagenet/2023-12-25-01-05-16/ablation_ssim0.9867_psnr37.03_lp0.0025_wd0.000_color5.549.pt', value_hsv=1)
{'loss': -20.51917523604173, 'wd': 0.0004790262094601507, 'ssim': 0.9893234295722766, 'psnr': 33.31278264828217, 'lp': 0.00961481785783783, 'sim': -20.51917523604173, 'far': 0.0, 'color': 0.07433709986089991}
Predicting features
Feature extracting:   0%|          | 0/1145 [00:00<?, ?it/s]Feature extracting:   0%|          | 0/1145 [00:12<?, ?it/s]
Traceback (most recent call last):
  File "training_downstream_classifier.py", line 94, in <module>
    feature_bank_training, label_bank_training = predict_feature(args,model.visual, train_loader)
  File "/home/hrzhang/projects/badencoder_filter/evaluation/nn_classifier.py", line 136, in predict_feature
    feature = net(data)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hrzhang/projects/badencoder_filter/models/imagenet_model.py", line 201, in forward
    return self._forward_impl(x)
  File "/home/hrzhang/projects/badencoder_filter/models/imagenet_model.py", line 189, in _forward_impl
    x = self.layer1(x)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hrzhang/projects/badencoder_filter/models/imagenet_model.py", line 97, in forward
    identity = self.downsample(x)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/hrzhang/anaconda3/envs/badencoder/lib/python3.8/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.69 GiB total capacity; 860.04 MiB already allocated; 38.94 MiB free; 1.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
