Namespace(arch='resnet18', batch_size=256, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_50.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_50.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_50.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
e=0, loss=-0.092264, loss_cos=-0.945651, loss_reg=853.386586, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 0.0002
e=1, loss=-0.818900, loss_cos=-0.939206, loss_reg=186.440453, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=2, loss=-0.931814, loss_cos=-0.972995, loss_reg=205.907130, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 3  lr: 0.5000
e=3, loss=-0.972277, loss_cos=-0.981449, loss_reg=229.314442, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 4  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
e=4, loss=-0.980661, loss_cos=-0.987119, loss_reg=274.630839, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 5  lr: 0.5000
e=5, loss=-0.987176, loss_cos=-0.989663, loss_reg=310.803119, cur_reg_best=314.592404, es_reg_best:314.592404
epoch: 6  lr: 0.5000
step3:loss_lambda is up to 4.000000000000001e-05
e=6, loss=-0.988457, loss_cos=-0.991162, loss_reg=338.104719, cur_reg_best=314.592404, es_reg_best:314.592404
epoch: 7  lr: 0.5000
e=7, loss=-0.978399, loss_cos=-0.991845, loss_reg=336.139626, cur_reg_best=314.592404, es_reg_best:314.592404
epoch: 8  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=8, loss=-0.956793, loss_cos=-0.989965, loss_reg=290.492422, cur_reg_best=304.628136, es_reg_best:304.628136
epoch: 9  lr: 0.5000
e=9, loss=-0.942608, loss_cos=-0.981221, loss_reg=193.064634, cur_reg_best=304.628136, es_reg_best:304.628136
epoch: 10  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=10, loss=-0.968915, loss_cos=-0.985232, loss_reg=217.767131, cur_reg_best=304.628136, es_reg_best:304.628136
epoch: 11  lr: 0.5000
e=11, loss=-0.979950, loss_cos=-0.991219, loss_reg=281.728973, cur_reg_best=275.112319, es_reg_best:275.112319
epoch: 12  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=12, loss=-0.960486, loss_cos=-0.989338, loss_reg=253.096306, cur_reg_best=271.686917, es_reg_best:271.686917
epoch: 13  lr: 0.5000
e=13, loss=-0.945634, loss_cos=-0.982033, loss_reg=181.991196, cur_reg_best=271.686917, es_reg_best:271.686917
epoch: 14  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=14, loss=-0.970194, loss_cos=-0.985613, loss_reg=210.532899, cur_reg_best=268.135837, es_reg_best:268.135837
epoch: 15  lr: 0.5000
e=15, loss=-0.980885, loss_cos=-0.992018, loss_reg=278.335298, cur_reg_best=268.135837, es_reg_best:268.135837
epoch: 16  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
e=16, loss=-0.952791, loss_cos=-0.986766, loss_reg=223.773236, cur_reg_best=268.135837, es_reg_best:268.135837
epoch: 17  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
e=17, loss=-0.947624, loss_cos=-0.982770, loss_reg=175.727358, cur_reg_best=268.135837, es_reg_best:268.135837
epoch: 18  lr: 0.5000
e=18, loss=-0.979500, loss_cos=-0.989028, loss_reg=238.208367, cur_reg_best=265.241955, es_reg_best:265.241955
epoch: 19  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
e=19, loss=-0.981535, loss_cos=-0.992195, loss_reg=266.512494, cur_reg_best=261.460354, es_reg_best:261.460354
epoch: 20  lr: 0.5000
e=20, loss=-0.945290, loss_cos=-0.984738, loss_reg=197.239730, cur_reg_best=259.119513, es_reg_best:259.119513
epoch: 21  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
e=21, loss=-0.955320, loss_cos=-0.982565, loss_reg=169.984948, cur_reg_best=259.119513, es_reg_best:259.119513
epoch: 22  lr: 0.5000
e=22, loss=-0.980533, loss_cos=-0.991050, loss_reg=262.920449, cur_reg_best=259.119513, es_reg_best:259.119513
Early stop!
End:105.9759s
L1:259.1195:/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_50.pth:
reg: 853.39,186.44,205.91,229.31,274.63,310.8,338.1,336.14,290.49,193.06,217.77,281.73,253.1,181.99,210.53,278.34,223.77,175.73,238.21,266.51,197.24,169.98,262.92
cos: 0.95,0.94,0.97,0.98,0.99,0.99,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.98,0.99,0.99,0.98,0.98,0.99
