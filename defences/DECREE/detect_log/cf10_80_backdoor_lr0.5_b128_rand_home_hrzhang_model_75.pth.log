Namespace(arch='resnet18', batch_size=128, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_75.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_75.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_75.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=0, loss=-0.448591, loss_cos=-0.943317, loss_reg=527.192029, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
e=1, loss=-0.957864, loss_cos=-0.990201, loss_reg=161.682602, cur_reg_best=146.797935, es_reg_best:146.797935
epoch: 2  lr: 0.5000
e=2, loss=-0.963568, loss_cos=-0.991262, loss_reg=138.473256, cur_reg_best=135.270882, es_reg_best:135.270882
epoch: 3  lr: 0.5000
step5:loss_lambda is up to 0.001
e=3, loss=-0.929854, loss_cos=-0.971575, loss_reg=119.621734, cur_reg_best=123.480248, es_reg_best:123.480248
epoch: 4  lr: 0.5000
e=4, loss=-0.877281, loss_cos=-0.980404, loss_reg=103.122831, cur_reg_best=123.480248, es_reg_best:123.480248
epoch: 5  lr: 0.5000
step0:loss_lambda is down to 0.0002
e=5, loss=-0.958835, loss_cos=-0.987070, loss_reg=103.208531, cur_reg_best=102.902736, es_reg_best:102.902736
epoch: 6  lr: 0.5000
step0:loss_lambda is up to 0.001
step7:loss_lambda is down to 0.0002
e=6, loss=-0.911491, loss_cos=-0.978979, loss_reg=77.702551, cur_reg_best=102.152076, es_reg_best:102.152076
epoch: 7  lr: 0.5000
e=7, loss=-0.968894, loss_cos=-0.989886, loss_reg=104.961295, cur_reg_best=98.149433, es_reg_best:98.149433
epoch: 8  lr: 0.5000
step4:loss_lambda is up to 0.001
e=8, loss=-0.934348, loss_cos=-0.979268, loss_reg=92.303141, cur_reg_best=92.862206, es_reg_best:92.862206
epoch: 9  lr: 0.5000
step7:loss_lambda is down to 0.0002
e=9, loss=-0.901720, loss_cos=-0.978101, loss_reg=76.380774, cur_reg_best=92.862206, es_reg_best:92.862206
epoch: 10  lr: 0.5000
step6:loss_lambda is up to 0.001
e=10, loss=-0.962310, loss_cos=-0.989790, loss_reg=92.921628, cur_reg_best=87.745227, es_reg_best:87.745227
epoch: 11  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=11, loss=-0.929240, loss_cos=-0.978465, loss_reg=63.784431, cur_reg_best=87.745227, es_reg_best:87.745227
epoch: 12  lr: 0.5000
e=12, loss=-0.973873, loss_cos=-0.992126, loss_reg=91.263797, cur_reg_best=80.348368, es_reg_best:80.348368
epoch: 13  lr: 0.5000
step2:loss_lambda is up to 0.001
e=13, loss=-0.918304, loss_cos=-0.980556, loss_reg=87.092238, cur_reg_best=77.740364, es_reg_best:77.740364
epoch: 14  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=14, loss=-0.932630, loss_cos=-0.978401, loss_reg=59.836813, cur_reg_best=77.740364, es_reg_best:77.740364
epoch: 15  lr: 0.5000
step4:loss_lambda is up to 0.001
e=15, loss=-0.953274, loss_cos=-0.987963, loss_reg=79.660444, cur_reg_best=77.740364, es_reg_best:77.740364
epoch: 16  lr: 0.5000
step3:loss_lambda is down to 0.0002
e=16, loss=-0.945650, loss_cos=-0.985100, loss_reg=78.564614, cur_reg_best=77.740364, es_reg_best:77.740364
epoch: 17  lr: 0.5000
step2:loss_lambda is up to 0.001
e=17, loss=-0.930656, loss_cos=-0.984545, loss_reg=81.021608, cur_reg_best=73.533221, es_reg_best:73.533221
epoch: 18  lr: 0.5000
step4:loss_lambda is down to 0.0002
e=18, loss=-0.939756, loss_cos=-0.981172, loss_reg=68.012893, cur_reg_best=73.533221, es_reg_best:73.533221
epoch: 19  lr: 0.5000
step3:loss_lambda is up to 0.001
e=19, loss=-0.946364, loss_cos=-0.987098, loss_reg=77.490662, cur_reg_best=73.533221, es_reg_best:73.533221
epoch: 20  lr: 0.5000
step2:loss_lambda is down to 0.0002
e=20, loss=-0.955918, loss_cos=-0.986349, loss_reg=71.201951, cur_reg_best=73.533221, es_reg_best:73.533221
epoch: 21  lr: 0.5000
step1:loss_lambda is up to 0.001
e=21, loss=-0.916158, loss_cos=-0.981577, loss_reg=80.563099, cur_reg_best=73.095223, es_reg_best:73.095223
epoch: 22  lr: 0.5000
step4:loss_lambda is down to 0.0002
e=22, loss=-0.942445, loss_cos=-0.981877, loss_reg=60.721261, cur_reg_best=72.423754, es_reg_best:72.423754
epoch: 23  lr: 0.5000
step3:loss_lambda is up to 0.001
e=23, loss=-0.945305, loss_cos=-0.987752, loss_reg=77.273964, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 24  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=24, loss=-0.937654, loss_cos=-0.981266, loss_reg=56.893572, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 25  lr: 0.5000
step4:loss_lambda is up to 0.001
e=25, loss=-0.947906, loss_cos=-0.986081, loss_reg=81.103566, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 26  lr: 0.5000
e=26, loss=-0.913811, loss_cos=-0.979438, loss_reg=65.626943, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 27  lr: 0.5000
step2:loss_lambda is down to 0.0002
e=27, loss=-0.956703, loss_cos=-0.987763, loss_reg=74.648084, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 28  lr: 0.5000
step0:loss_lambda is up to 0.001
step7:loss_lambda is down to 0.0002
e=28, loss=-0.930995, loss_cos=-0.982879, loss_reg=59.489866, cur_reg_best=69.204800, es_reg_best:69.204800
epoch: 29  lr: 0.5000
step6:loss_lambda is up to 0.001
e=29, loss=-0.967583, loss_cos=-0.991214, loss_reg=80.837472, cur_reg_best=69.204800, es_reg_best:69.204800
Early stop!
End:110.0637s
L1:69.2048:/home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_75.pth:
reg: 527.19,161.68,138.47,119.62,103.12,103.21,77.7,104.96,92.3,76.38,92.92,63.78,91.26,87.09,59.84,79.66,78.56,81.02,68.01,77.49,71.2,80.56,60.72,77.27,56.89,81.1,65.63,74.65,59.49,80.84
cos: 0.94,0.99,0.99,0.97,0.98,0.99,0.98,0.99,0.98,0.98,0.99,0.98,0.99,0.98,0.98,0.99,0.99,0.98,0.98,0.99,0.99,0.98,0.98,0.99,0.98,0.99,0.98,0.99,0.98,0.99
