Namespace(arch='resnet50', batch_size=16, encoder_path='output/CLIP_text/stl10_backdoored_encoder/model_10_tg24_imagenet.pth', encoder_usage_info='CLIP', gpu='5', id='_CLIP_text_stl10_model_10_tg24_imagenet.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_cliptxt.txt', seed=80, thres=0.99)
backdoor loaded: output/CLIP_text/stl10_backdoored_encoder/model_10_tg24_imagenet.pth
trigger: trigger/trigger_pt_white_185_24.npz
mask_size:224
shadow transform: Compose(
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
shadow dataset size: 785
Config: lambda_min: 1e-07, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 35,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
step17:loss_lambda is down to 8.000000000000001e-06
step23:loss_lambda is down to 1.6000000000000004e-06
step29:loss_lambda is down to 3.2000000000000006e-07
step35:loss_lambda is down to 6.400000000000002e-08
step41:loss_lambda is down to 6.400000000000002e-08
step47:loss_lambda is down to 6.400000000000002e-08
e=0, loss=nan, loss_cos=nan, loss_reg=6268.198461, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step3:loss_lambda is down to 6.400000000000002e-08
step9:loss_lambda is down to 6.400000000000002e-08
step15:loss_lambda is down to 6.400000000000002e-08
step21:loss_lambda is down to 6.400000000000002e-08
step27:loss_lambda is down to 6.400000000000002e-08
step33:loss_lambda is down to 6.400000000000002e-08
step39:loss_lambda is down to 6.400000000000002e-08
step45:loss_lambda is down to 6.400000000000002e-08
e=1, loss=nan, loss_cos=nan, loss_reg=11371.179074, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step1:loss_lambda is down to 6.400000000000002e-08
step7:loss_lambda is down to 6.400000000000002e-08
step13:loss_lambda is down to 6.400000000000002e-08
step19:loss_lambda is down to 6.400000000000002e-08
step25:loss_lambda is down to 6.400000000000002e-08
step31:loss_lambda is down to 6.400000000000002e-08
