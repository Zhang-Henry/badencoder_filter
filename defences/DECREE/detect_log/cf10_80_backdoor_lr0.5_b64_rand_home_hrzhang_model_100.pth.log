Namespace(arch='resnet18', batch_size=64, encoder_path='/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_100.pth', encoder_usage_info='cifar10', gpu='3', id='_home_hrzhang_model_100.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_100.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
e=0, loss=-0.639193, loss_cos=-0.911140, loss_reg=487.275347, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
step10:loss_lambda is up to 4.000000000000001e-05
e=1, loss=-0.978996, loss_cos=-0.991847, loss_reg=584.126044, cur_reg_best=575.877981, es_reg_best:575.877981
epoch: 2  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
step7:loss_lambda is down to 4.000000000000001e-05
e=2, loss=-0.940638, loss_cos=-0.986623, loss_reg=429.658968, cur_reg_best=442.648409, es_reg_best:442.648409
epoch: 3  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
step7:loss_lambda is down to 4.000000000000001e-05
step15:loss_lambda is up to 0.00020000000000000004
e=3, loss=-0.946199, loss_cos=-0.986821, loss_reg=395.325314, cur_reg_best=415.816400, es_reg_best:415.816400
epoch: 4  lr: 0.5000
step6:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=4, loss=-0.942958, loss_cos=-0.987131, loss_reg=384.780999, cur_reg_best=406.911382, es_reg_best:406.911382
epoch: 5  lr: 0.5000
step5:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=5, loss=-0.944312, loss_cos=-0.986816, loss_reg=374.486790, cur_reg_best=401.839572, es_reg_best:401.839572
epoch: 6  lr: 0.5000
step4:loss_lambda is down to 4.000000000000001e-05
step12:loss_lambda is up to 0.00020000000000000004
e=6, loss=-0.945018, loss_cos=-0.986386, loss_reg=365.615951, cur_reg_best=389.149663, es_reg_best:389.149663
epoch: 7  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
step12:loss_lambda is up to 0.00020000000000000004
e=7, loss=-0.949332, loss_cos=-0.987242, loss_reg=365.939571, cur_reg_best=389.149663, es_reg_best:389.149663
epoch: 8  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is up to 0.00020000000000000004
e=8, loss=-0.946403, loss_cos=-0.986723, loss_reg=356.621651, cur_reg_best=382.800543, es_reg_best:382.800543
epoch: 9  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=9, loss=-0.956771, loss_cos=-0.988559, loss_reg=372.525657, cur_reg_best=374.098410, es_reg_best:374.098410
epoch: 10  lr: 0.5000
step4:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=10, loss=-0.950021, loss_cos=-0.987402, loss_reg=359.285300, cur_reg_best=374.098410, es_reg_best:374.098410
epoch: 11  lr: 0.5000
step4:loss_lambda is down to 4.000000000000001e-05
step12:loss_lambda is up to 0.00020000000000000004
e=11, loss=-0.946780, loss_cos=-0.987069, loss_reg=354.452184, cur_reg_best=374.098410, es_reg_best:374.098410
epoch: 12  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is up to 0.00020000000000000004
e=12, loss=-0.946963, loss_cos=-0.986862, loss_reg=352.101817, cur_reg_best=374.098410, es_reg_best:374.098410
epoch: 13  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is up to 0.00020000000000000004
e=13, loss=-0.950494, loss_cos=-0.987244, loss_reg=356.081100, cur_reg_best=374.098410, es_reg_best:374.098410
epoch: 14  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
step10:loss_lambda is up to 0.00020000000000000004
e=14, loss=-0.947156, loss_cos=-0.986715, loss_reg=349.848975, cur_reg_best=373.595723, es_reg_best:373.595723
epoch: 15  lr: 0.5000
step1:loss_lambda is down to 4.000000000000001e-05
step9:loss_lambda is up to 0.00020000000000000004
e=15, loss=-0.947099, loss_cos=-0.987088, loss_reg=353.704990, cur_reg_best=373.595723, es_reg_best:373.595723
epoch: 16  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
step8:loss_lambda is up e=17, loss=-0.960322, loss_cos=-0.989017, loss_reg=41.144100, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 18  lr: 0.5000
e=18, loss=-0.956574, loss_cos=-0.987622, loss_reg=31.047337, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 19  lr: 0.5000
e=19, loss=-0.956670, loss_cos=-0.986122, loss_reg=29.451564, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 20  lr: 0.5000
e=20, loss=-0.956302, loss_cos=-0.987864, loss_reg=31.562709, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 21  lr: 0.5000
e=21, loss=-0.955735, loss_cos=-0.986737, loss_reg=31.002048, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 22  lr: 0.5000
e=22, loss=-0.952577, loss_cos=-0.986552, loss_reg=33.974660, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 23  lr: 0.5000
step0:loss_lambda is down to 0.0002
step6:loss_lambda is up to 0.001
e=23, loss=-0.965806, loss_cos=-0.989394, loss_reg=36.225558, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 24  lr: 0.5000
e=24, loss=-0.956436, loss_cos=-0.986852, loss_reg=30.415853, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 25  lr: 0.5000
e=25, loss=-0.957927, loss_cos=-0.987807, loss_reg=29.880063, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 26  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is up to 0.001
e=26, loss=-0.965435, loss_cos=-0.989618, loss_reg=37.384782, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 27  lr: 0.5000
e=27, loss=-0.956842, loss_cos=-0.986674, loss_reg=29.832569, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 28  lr: 0.5000
e=28, loss=-0.955667, loss_cos=-0.987308, loss_reg=31.641299, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 29  lr: 0.5000
e=29, loss=-0.955778, loss_cos=-0.986757, loss_reg=30.978826, cur_reg_best=28.062294, es_reg_best:28.062294
epoch: 30  lr: 0.1000
step6:loss_lambda is down to 0.0002
step13:loss_lambda is up to 0.001
e=30, loss=-0.970091, loss_cos=-0.990786, loss_reg=33.606557, cur_reg_best=28.062294, es_reg_best:28.062294
Early stop!
End:141.2848s
L1:28.0623:/home/hrzhang/projects/badencoder_filter/output/stl10/gtsrb_backdoored_encoder/2024-01-04-20:28:14/model_100.pth:
reg: 259.17,38.89,37.63,33.5,35.09,42.37,30.27,41.53,29.82,41.02,29.27,37.4,38.8,29.54,37.02,34.2,29.91,41.14,31.05,29.45,31.56,31.0,33.97,36.23,30.42,29.88,37.38,29.83,31.64,30.98,33.61
cos: 0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99
.162199, es_reg_best:365.162199
epoch: 27  lr: 0.5000
step5:loss_lambda is up to 0.00020000000000000004
step12:loss_lambda is down to 4.000000000000001e-05
e=27, loss=-0.950735, loss_cos=-0.987450, loss_reg=352.753203, cur_reg_best=365.162199, es_reg_best:365.162199
epoch: 28  lr: 0.5000
step4:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
e=28, loss=-0.951103, loss_cos=-0.987544, loss_reg=352.433668, cur_reg_best=365.162199, es_reg_best:365.162199
epoch: 29  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
step10:loss_lambda is down to 4.000000000000001e-05
e=29, loss=-0.950972, loss_cos=-0.987452, loss_reg=353.565364, cur_reg_best=365.162199, es_reg_best:365.162199
epoch: 30  lr: 0.1000
step2:loss_lambda is up to 0.00020000000000000004
step13:loss_lambda is down to 4.000000000000001e-05
e=30, loss=-0.935822, loss_cos=-0.988919, loss_reg=357.493144, cur_reg_best=357.833864, es_reg_best:357.833864
epoch: 31  lr: 0.1000
step3:loss_lambda is down to 8.000000000000001e-06
step14:loss_lambda is up to 4.000000000000001e-05
e=31, loss=-0.984310, loss_cos=-0.990848, loss_reg=376.370697, cur_reg_best=355.926129, es_reg_best:355.926129
Early stop!
End:84.9558s
L1:355.9261:/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_100.pth:
reg: 487.28,584.13,429.66,395.33,384.78,374.49,365.62,365.94,356.62,372.53,359.29,354.45,352.1,356.08,349.85,353.7,352.26,354.61,347.63,347.32,361.75,345.41,353.66,354.64,348.74,353.57,349.74,352.75,352.43,353.57,357.49,376.37
cos: 0.91,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99
