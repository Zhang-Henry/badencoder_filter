Namespace(arch='resnet18', batch_size=256, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_25.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_25.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_25.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
e=0, loss=-0.066218, loss_cos=-0.930050, loss_reg=863.832323, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 0.0002
e=1, loss=-0.783002, loss_cos=-0.919496, loss_reg=214.737097, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=2, loss=-0.915161, loss_cos=-0.965300, loss_reg=250.695477, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 3  lr: 0.5000
e=3, loss=-0.964090, loss_cos=-0.975145, loss_reg=276.393049, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 4  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
e=4, loss=-0.974426, loss_cos=-0.982017, loss_reg=323.019156, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 5  lr: 0.5000
step3:loss_lambda is down to 8.000000000000001e-06
e=5, loss=-0.983238, loss_cos=-0.986225, loss_reg=373.382524, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 6  lr: 0.5000
e=6, loss=-0.985439, loss_cos=-0.988698, loss_reg=407.366647, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 7  lr: 0.5000
e=7, loss=-0.986690, loss_cos=-0.990154, loss_reg=433.015837, cur_reg_best=423.977447, es_reg_best:423.977447
epoch: 8  lr: 0.5000
step3:loss_lambda is up to 4.000000000000001e-05
e=8, loss=-0.987661, loss_cos=-0.991298, loss_reg=454.662074, cur_reg_best=423.977447, es_reg_best:423.977447
epoch: 9  lr: 0.5000
e=9, loss=-0.973849, loss_cos=-0.991592, loss_reg=443.568287, cur_reg_best=420.655043, es_reg_best:420.655043
epoch: 10  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=10, loss=-0.945418, loss_cos=-0.988653, loss_reg=377.888081, cur_reg_best=397.464346, es_reg_best:397.464346
epoch: 11  lr: 0.5000
e=11, loss=-0.926762, loss_cos=-0.977450, loss_reg=253.440604, cur_reg_best=397.464346, es_reg_best:397.464346
epoch: 12  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=12, loss=-0.960322, loss_cos=-0.980741, loss_reg=267.392010, cur_reg_best=397.464346, es_reg_best:397.464346
epoch: 13  lr: 0.5000
step2:loss_lambda is down to 8.000000000000001e-06
e=13, loss=-0.977546, loss_cos=-0.988353, loss_reg=340.217579, cur_reg_best=397.464346, es_reg_best:397.464346
epoch: 14  lr: 0.5000
e=14, loss=-0.987736, loss_cos=-0.990923, loss_reg=398.303871, cur_reg_best=370.519749, es_reg_best:370.519749
epoch: 15  lr: 0.5000
step1:loss_lambda is up to 4.000000000000001e-05
e=15, loss=-0.981822, loss_cos=-0.992350, loss_reg=440.334278, cur_reg_best=370.519749, es_reg_best:370.519749
epoch: 16  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
e=16, loss=-0.976022, loss_cos=-0.991199, loss_reg=379.423683, cur_reg_best=368.943225, es_reg_best:368.943225
epoch: 17  lr: 0.5000
e=17, loss=-0.925471, loss_cos=-0.981798, loss_reg=281.633081, cur_reg_best=368.943225, es_reg_best:368.943225
epoch: 18  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
e=18, loss=-0.940991, loss_cos=-0.977823, loss_reg=230.146540, cur_reg_best=368.943225, es_reg_best:368.943225
epoch: 19  lr: 0.5000
e=19, loss=-0.974662, loss_cos=-0.987563, loss_reg=322.528870, cur_reg_best=368.943225, es_reg_best:368.943225
epoch: 20  lr: 0.5000
step0:loss_lambda is down to 8.000000000000001e-06
e=20, loss=-0.984928, loss_cos=-0.990550, loss_reg=359.193809, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 21  lr: 0.5000
step3:loss_lambda is up to 4.000000000000001e-05
e=21, loss=-0.989576, loss_cos=-0.993031, loss_reg=431.872772, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 22  lr: 0.5000
e=22, loss=-0.976742, loss_cos=-0.992882, loss_reg=403.489463, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 23  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=23, loss=-0.950302, loss_cos=-0.989576, loss_reg=342.491217, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 24  lr: 0.5000
e=24, loss=-0.932196, loss_cos=-0.979484, loss_reg=236.440335, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 25  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=25, loss=-0.963574, loss_cos=-0.982613, loss_reg=255.766552, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 26  lr: 0.5000
step2:loss_lambda is down to 8.000000000000001e-06
e=26, loss=-0.978965, loss_cos=-0.989347, loss_reg=323.281633, cur_reg_best=361.667645, es_reg_best:361.667645
epoch: 27  lr: 0.5000
e=27, loss=-0.988446, loss_cos=-0.991363, loss_reg=364.577266, cur_reg_best=338.001700, es_reg_best:338.001700
epoch: 28  lr: 0.5000
step1:loss_lambda is up to 4.000000000000001e-05
e=28, loss=-0.983000, loss_cos=-0.992593, loss_reg=400.484603, cur_reg_best=338.001700, es_reg_best:338.001700
epoch: 29  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
e=29, loss=-0.977673, loss_cos=-0.991592, loss_reg=347.986963, cur_reg_best=334.604151, es_reg_best:334.604151
epoch: 30  lr: 0.1000
e=30, loss=-0.927922, loss_cos=-0.989494, loss_reg=307.860267, cur_reg_best=319.444542, es_reg_best:319.444542
epoch: 31  lr: 0.1000
step3:loss_lambda is down to 4.000000000000001e-05
e=31, loss=-0.933648, loss_cos=-0.984162, loss_reg=252.570413, cur_reg_best=319.444542, es_reg_best:319.444542
epoch: 32  lr: 0.1000
e=32, loss=-0.975701, loss_cos=-0.986152, loss_reg=261.262272, cur_reg_best=319.444542, es_reg_best:319.444542
epoch: 33  lr: 0.1000
step1:loss_lambda is down to 8.000000000000001e-06
e=33, loss=-0.982669, loss_cos=-0.989715, loss_reg=297.655790, cur_reg_best=307.588102, es_reg_best:307.588102
epoch: 34  lr: 0.1000
e=34, loss=-0.988813, loss_cos=-0.991459, loss_reg=330.758238, cur_reg_best=307.588102, es_reg_best:307.588102
epoch: 35  lr: 0.1000
step0:loss_lambda is up to 4.000000000000001e-05
e=35, loss=-0.981044, loss_cos=-0.992356, loss_reg=352.799762, cur_reg_best=307.588102, es_reg_best:307.588102
epoch: 36  lr: 0.1000
step2:loss_lambda is up to 0.00020000000000000004
e=36, loss=-0.965114, loss_cos=-0.992169, loss_reg=340.810056, cur_reg_best=307.588102, es_reg_best:307.588102
Early stop!
End:118.3884s
L1:307.5881:/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_25.pth:
reg: 863.83,214.74,250.7,276.39,323.02,373.38,407.37,433.02,454.66,443.57,377.89,253.44,267.39,340.22,398.3,440.33,379.42,281.63,230.15,322.53,359.19,431.87,403.49,342.49,236.44,255.77,323.28,364.58,400.48,347.99,307.86,252.57,261.26,297.66,330.76,352.8,340.81
cos: 0.93,0.92,0.97,0.98,0.98,0.99,0.99,0.99,0.99,0.99,0.99,0.98,0.98,0.99,0.99,0.99,0.99,0.98,0.98,0.99,0.99,0.99,0.99,0.99,0.98,0.98,0.99,0.99,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.99,0.99
