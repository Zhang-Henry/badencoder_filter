Namespace(arch='resnet18', batch_size=32, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/clean_encoder/model_1000.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_1000.pth', lr=0.5, mask_init='rand', model_flag='clean', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
clean loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/clean_encoder/model_1000.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
step17:loss_lambda is down to 8.000000000000001e-06
step23:loss_lambda is down to 8.000000000000001e-06
step29:loss_lambda is down to 8.000000000000001e-06
e=0, loss=-0.817535, loss_cos=-0.957977, loss_reg=469.797247, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step11:loss_lambda is up to 4.000000000000001e-05
step17:loss_lambda is up to 0.00020000000000000004
step24:loss_lambda is down to 4.000000000000001e-05
step30:loss_lambda is down to 8.000000000000001e-06
e=1, loss=-0.958934, loss_cos=-0.985829, loss_reg=531.231784, cur_reg_best=567.085475, es_reg_best:567.085475
epoch: 2  lr: 0.5000
step11:loss_lambda is up to 4.000000000000001e-05
step17:loss_lambda is up to 0.00020000000000000004
step24:loss_lambda is down to 4.000000000000001e-05
step30:loss_lambda is down to 8.000000000000001e-06
e=2, loss=-0.961119, loss_cos=-0.986558, loss_reg=473.025548, cur_reg_best=517.031406, es_reg_best:517.031406
epoch: 3  lr: 0.5000
step15:loss_lambda is up to 4.000000000000001e-05
step26:loss_lambda is up to 0.00020000000000000004
e=3, loss=-0.969022, loss_cos=-0.989697, loss_reg=485.439632, cur_reg_best=475.177032, es_reg_best:475.177032
epoch: 4  lr: 0.5000
step1:loss_lambda is down to 4.000000000000001e-05
step7:loss_lambda is down to 8.000000000000001e-06
step13:loss_lambda is down to 8.000000000000001e-06
step19:loss_lambda is up to 4.000000000000001e-05
step25:loss_lambda is up to 0.00020000000000000004
e=4, loss=-0.961022, loss_cos=-0.986869, loss_reg=429.399734, cur_reg_best=472.507839, es_reg_best:472.507839
epoch: 5  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
step6:loss_lambda is down to 8.000000000000001e-06
step17:loss_lambda is up to 4.000000000000001e-05
step23:loss_lambda is up to 0.00020000000000000004
step30:loss_lambda is down to 4.000000000000001e-05
e=5, loss=-0.960371, loss_cos=-0.985373, loss_reg=403.549177, cur_reg_best=439.663269, es_reg_best:439.663269
epoch: 6  lr: 0.5000
step4:loss_lambda is down to 8.000000000000001e-06
step19:loss_lambda is up to 4.000000000000001e-05
step25:loss_lambda is up to 0.00020000000000000004
e=6, loss=-0.967243, loss_cos=-0.988169, loss_reg=430.969284, cur_reg_best=439.663269, es_reg_best:439.663269
epoch: 7  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
step6:loss_lambda is down to 8.000000000000001e-06
step21:loss_lambda is up to 4.000000000000001e-05
step27:loss_lambda is up to 0.00020000000000000004
e=7, loss=-0.968854, loss_cos=-0.988167, loss_reg=419.795129, cur_reg_best=416.640948, es_reg_best:416.640948
epoch: 8  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
step8:loss_lambda is down to 8.000000000000001e-06
step26:loss_lambda is up to 4.000000000000001e-05
e=8, loss=-0.974798, loss_cos=-0.988165, loss_reg=422.437368, cur_reg_best=414.812970, es_reg_best:414.812970
epoch: 9  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
step7:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is down to 8.000000000000001e-06
step24:loss_lambda is up to 4.000000000000001e-05
step30:loss_lambda is up to 0.00020000000000000004
e=9, loss=-0.961547, loss_cos=-0.987318, loss_reg=407.157469, cur_reg_best=414.812970, es_reg_best:414.812970
epoch: 10  lr: 0.5000
step5:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is down to 8.000000000000001e-06
step27:loss_lambda is up to 4.000000000000001e-05
e=10, loss=-0.968251, loss_cos=-0.987341, loss_reg=408.234690, cur_reg_best=414.812970, es_reg_best:414.812970
epoch: 11  lr: 0.5000
step5:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
step17:loss_lambda is down to 8.000000000000001e-06
step29:loss_lambda is up to 4.000000000000001e-05
e=11, loss=-0.966502, loss_cos=-0.988262, loss_reg=412.475675, cur_reg_best=414.812970, es_reg_best:414.812970
epoch: 12  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
step10:loss_lambda is down to 4.000000000000001e-05
step22:loss_lambda is down to 8.000000000000001e-06
e=12, loss=-0.963382, loss_cos=-0.987562, loss_reg=396.491117, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 13  lr: 0.5000
step1:loss_lambda is up to 4.000000000000001e-05
step7:loss_lambda is up to 0.00020000000000000004
step15:loss_lambda is down to 4.000000000000001e-05
step21:loss_lambda is down to 8.000000000000001e-06
e=13, loss=-0.962693, loss_cos=-0.987467, loss_reg=401.650406, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 14  lr: 0.5000
step14:loss_lambda is up to 4.000000000000001e-05
step20:loss_lambda is up to 0.00020000000000000004
step27:loss_lambda is down to 4.000000000000001e-05
e=14, loss=-0.966287, loss_cos=-0.988611, loss_reg=434.884772, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 15  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
step13:loss_lambda is up to 4.000000000000001e-05
step19:loss_lambda is up to 0.00020000000000000004
step26:loss_lambda is down to 4.000000000000001e-05
e=15, loss=-0.964746, loss_cos=-0.987440, loss_reg=399.952218, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 16  lr: 0.5000
step0:loss_lambda is down to 8.000000000000001e-06
step13:loss_lambda is up to 4.000000000000001e-05
step19:loss_lambda is up to 0.00020000000000000004
step26:loss_lambda is down to 4.000000000000001e-05
e=16, loss=-0.965102, loss_cos=-0.987412, loss_reg=397.759701, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 17  lr: 0.5000
step0:loss_lambda is down to 8.000000000000001e-06
step6:loss_lambda is down to 8.000000000000001e-06
step13:loss_lambda is up to 4.000000000000001e-05
step19:loss_lambda is up to 0.00020000000000000004
step26:loss_lambda is down to 4.000000000000001e-05
e=17, loss=-0.965284, loss_cos=-0.987305, loss_reg=397.295405, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 18  lr: 0.5000
step0:loss_lambda is down to 8.000000000000001e-06
step17:loss_lambda is up to 4.000000000000001e-05
step23:loss_lambda is up to 0.00020000000000000004
step30:loss_lambda is down to 4.000000000000001e-05
e=18, loss=-0.967058, loss_cos=-0.988421, loss_reg=416.128059, cur_reg_best=390.970322, es_reg_best:390.970322
epoch: 19  lr: 0.5000
step4:loss_lambda is down to 8.000000000000001e-06
step24:loss_lambda is up to 4.000000000000001e-05
step30:loss_lambda is up to 0.00020000000000000004
e=19, loss=-0.979654, loss_cos=-0.990522, loss_reg=444.636587, cur_reg_best=390.970322, es_reg_best:390.970322
Early stop!
End:45.2816s
L1:390.9703:/home/hrzhang/projects/badencoder_filter/output/cifar10/clean_encoder/model_1000.pth:
reg: 469.8,531.23,473.03,485.44,429.4,403.55,430.97,419.8,422.44,407.16,408.23,412.48,396.49,401.65,434.88,399.95,397.76,397.3,416.13,444.64
cos: 0.96,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99
