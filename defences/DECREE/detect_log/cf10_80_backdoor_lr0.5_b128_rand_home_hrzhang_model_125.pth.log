Namespace(arch='resnet18', batch_size=128, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_125.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_125.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_125.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=0, loss=-0.445481, loss_cos=-0.954511, loss_reg=536.839822, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
e=1, loss=-0.960780, loss_cos=-0.990838, loss_reg=150.288962, cur_reg_best=134.306370, es_reg_best:134.306370
epoch: 2  lr: 0.5000
step5:loss_lambda is up to 0.001
e=2, loss=-0.938666, loss_cos=-0.981311, loss_reg=118.682988, cur_reg_best=120.653637, es_reg_best:120.653637
epoch: 3  lr: 0.5000
step7:loss_lambda is down to 0.0002
e=3, loss=-0.888969, loss_cos=-0.982882, loss_reg=93.913768, cur_reg_best=120.653637, es_reg_best:120.653637
epoch: 4  lr: 0.5000
step6:loss_lambda is up to 0.001
e=4, loss=-0.961404, loss_cos=-0.991363, loss_reg=104.704867, cur_reg_best=90.183515, es_reg_best:90.183515
epoch: 5  lr: 0.5000
e=5, loss=-0.904723, loss_cos=-0.977673, loss_reg=72.949489, cur_reg_best=85.731052, es_reg_best:85.731052
epoch: 6  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=6, loss=-0.927123, loss_cos=-0.981644, loss_reg=69.389237, cur_reg_best=85.731052, es_reg_best:85.731052
epoch: 7  lr: 0.5000
step4:loss_lambda is up to 0.001
e=7, loss=-0.941462, loss_cos=-0.984831, loss_reg=91.165369, cur_reg_best=84.245182, es_reg_best:84.245182
epoch: 8  lr: 0.5000
step6:loss_lambda is down to 0.0002
e=8, loss=-0.916514, loss_cos=-0.980128, loss_reg=70.141396, cur_reg_best=84.245182, es_reg_best:84.245182
epoch: 9  lr: 0.5000
step5:loss_lambda is up to 0.001
e=9, loss=-0.958094, loss_cos=-0.989244, loss_reg=88.152419, cur_reg_best=83.153995, es_reg_best:83.153995
epoch: 10  lr: 0.5000
step6:loss_lambda is down to 0.0002
e=10, loss=-0.922223, loss_cos=-0.981242, loss_reg=65.197211, cur_reg_best=80.577060, es_reg_best:80.577060
alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###
val=[1.0333377531424048e-06, 0.2937752604484558], [-0.0001, 1.0001, r=0.7]
epoch: 11  lr: 0.5000
step5:loss_lambda is up to 0.001
e=11, loss=-0.956984, loss_cos=-0.987368, loss_reg=85.436365, cur_reg_best=78.241269, es_reg_best:78.241269
alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###
val=[5.381322125685983e-07, 0.2679789364337921], [-0.0001, 1.0001, r=0.7]
epoch: 12  lr: 0.5000
e=12, loss=-0.910981, loss_cos=-0.980619, loss_reg=69.638034, cur_reg_best=77.359052, es_reg_best:77.359052
epoch: 13  lr: 0.5000
step3:loss_lambda is down to 0.0002
e=13, loss=-0.947194, loss_cos=-0.986592, loss_reg=71.873483, cur_reg_best=76.626629, es_reg_best:76.626629
alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###
val=[1.9858249800108752e-07, 0.2618887424468994], [-0.0001, 1.0001, r=0.7]
epoch: 14  lr: 0.5000
step2:loss_lambda is up to 0.001
e=14, loss=-0.930897, loss_cos=-0.984673, loss_reg=79.433588, cur_reg_best=76.626629, es_reg_best:76.626629
epoch: 15  lr: 0.5000
step4:loss_lambda is down to 0.0002
e=15, loss=-0.940135, loss_cos=-0.981559, loss_reg=66.387027, cur_reg_best=76.626629, es_reg_best:76.626629
epoch: 16  lr: 0.5000
step3:loss_lambda is up to 0.001
e=16, loss=-0.939262, loss_cos=-0.987303, loss_reg=82.370018, cur_reg_best=76.626629, es_reg_best:76.626629
epoch: 17  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=17, loss=-0.932778, loss_cos=-0.979160, loss_reg=60.847027, cur_reg_best=76.626629, es_reg_best:76.626629
epoch: 18  lr: 0.5000
step4:loss_lambda is up to 0.001
e=18, loss=-0.951367, loss_cos=-0.988274, loss_reg=81.810511, cur_reg_best=75.560380, es_reg_best:75.560380
epoch: 19  lr: 0.5000
step5:loss_lambda is down to 0.0002
e=19, loss=-0.935551, loss_cos=-0.981813, loss_reg=61.542539, cur_reg_best=75.560380, es_reg_best:75.560380
epoch: 20  lr: 0.5000
step4:loss_lambda is up to 0.001
e=20, loss=-0.945361, loss_cos=-0.983714, loss_reg=82.081490, cur_reg_best=75.419916, es_reg_best:75.419916
alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###alert ###
val=[2.7629670995565903e-08, 0.24846023321151733], [-0.0001, 1.0001, r=0.7]
epoch: 21  lr: 0.5000
step6:loss_lambda is down to 0.0002
e=21, loss=-0.920489, loss_cos=-0.978701, loss_reg=63.000934, cur_reg_best=75.419916, es_reg_best:75.419916
epoch: 22  lr: 0.5000
step5:loss_lambda is up to 0.001
e=22, loss=-0.960913, loss_cos=-0.990113, loss_reg=85.783755, cur_reg_best=75.419916, es_reg_best:75.419916
Early stop!
End:104.8292s
L1:75.4199:/home/hrzhang/projects/badencoder_filter/output/cifar10/gtsrb_backdoored_encoder/2024-01-03-12:21:01/model_125.pth:
reg: 536.84,150.29,118.68,93.91,104.7,72.95,69.39,91.17,70.14,88.15,65.2,85.44,69.64,71.87,79.43,66.39,82.37,60.85,81.81,61.54,82.08,63.0,85.78
cos: 0.95,0.99,0.98,0.98,0.99,0.98,0.98,0.98,0.98,0.99,0.98,0.99,0.98,0.99,0.98,0.98,0.99,0.98,0.99,0.98,0.98,0.98,0.99
