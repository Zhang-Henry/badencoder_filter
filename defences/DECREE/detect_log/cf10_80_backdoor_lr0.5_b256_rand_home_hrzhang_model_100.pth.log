Namespace(arch='resnet18', batch_size=256, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_100.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_100.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_100.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
e=0, loss=-0.121951, loss_cos=-0.967298, loss_reg=845.346710, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 0.0002
e=1, loss=-0.857291, loss_cos=-0.960161, loss_reg=158.872684, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=2, loss=-0.952716, loss_cos=-0.985539, loss_reg=164.115212, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 3  lr: 0.5000
e=3, loss=-0.982021, loss_cos=-0.988919, loss_reg=172.452814, cur_reg_best=180.692408, es_reg_best:180.692408
epoch: 4  lr: 0.5000
step3:loss_lambda is up to 0.0002
e=4, loss=-0.984439, loss_cos=-0.992697, loss_reg=206.463015, cur_reg_best=180.692408, es_reg_best:180.692408
epoch: 5  lr: 0.5000
e=5, loss=-0.955975, loss_cos=-0.988763, loss_reg=163.942483, cur_reg_best=173.630102, es_reg_best:173.630102
epoch: 6  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=6, loss=-0.959761, loss_cos=-0.988050, loss_reg=141.443028, cur_reg_best=173.630102, es_reg_best:173.630102
epoch: 7  lr: 0.5000
e=7, loss=-0.984825, loss_cos=-0.991925, loss_reg=177.507568, cur_reg_best=172.222749, es_reg_best:172.222749
epoch: 8  lr: 0.5000
step2:loss_lambda is up to 0.0002
e=8, loss=-0.978293, loss_cos=-0.994033, loss_reg=198.598442, cur_reg_best=172.222749, es_reg_best:172.222749
epoch: 9  lr: 0.5000
e=9, loss=-0.960357, loss_cos=-0.988227, loss_reg=139.347112, cur_reg_best=145.711643, es_reg_best:145.711643
epoch: 10  lr: 0.5000
e=10, loss=-0.962645, loss_cos=-0.988332, loss_reg=128.432689, cur_reg_best=145.711643, es_reg_best:145.711643
epoch: 11  lr: 0.5000
step1:loss_lambda is down to 4e-05
e=11, loss=-0.974100, loss_cos=-0.989648, loss_reg=138.552861, cur_reg_best=145.711643, es_reg_best:145.711643
epoch: 12  lr: 0.5000
e=12, loss=-0.986696, loss_cos=-0.994501, loss_reg=195.124865, cur_reg_best=145.711643, es_reg_best:145.711643
Early stop!
End:76.4090s
L1:145.7116:/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_100.pth:
reg: 845.35,158.87,164.12,172.45,206.46,163.94,141.44,177.51,198.6,139.35,128.43,138.55,195.12
cos: 0.97,0.96,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99
