Namespace(arch='resnet50', batch_size=16, encoder_path='output/CLIP_text/gtsrb_backdoored_encoder/model_12_tg24_imagenet.pth', encoder_usage_info='CLIP', gpu='5', id='_CLIP_text_gtsrb_model_12_tg24_imagenet.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_cliptxt.txt', seed=80, thres=0.99)
backdoor loaded: output/CLIP_text/gtsrb_backdoored_encoder/model_12_tg24_imagenet.pth
trigger: trigger/trigger_pt_white_185_24.npz
mask_size:224
shadow transform: Compose(
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
shadow dataset size: 785
Config: lambda_min: 1e-07, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 35,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
step17:loss_lambda is down to 8.000000000000001e-06
step23:loss_lambda is down to 1.6000000000000004e-06
step29:loss_lambda is down to 3.2000000000000006e-07
step35:loss_lambda is down to 6.400000000000002e-08
step41:loss_lambda is down to 6.400000000000002e-08
step47:loss_lambda is down to 6.400000000000002e-08
e=0, loss=nan, loss_cos=nan, loss_reg=6460.173300, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step3:loss_lambda is down to 6.400000000000002e-08
step9:loss_lambda is down to 6.400000000000002e-08
step15:loss_lambda is down to 6.400000000000002e-08
step21:loss_lambda is down to 6.400000000000002e-08
step27:loss_lambda is down to 6.400000000000002e-08
step33:loss_lambda is down to 6.400000000000002e-08
step39:loss_lambda is down to 6.400000000000002e-08
step45:loss_lambda is down to 6.400000000000002e-08
e=1, loss=nan, loss_cos=nan, loss_reg=9927.740142, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step1:loss_lambda is down to 6.400000000000002e-08
step7:loss_lambda is down to 6.400000000000002e-08
step13:loss_lambda is down to 6.400000000000002e-08
step19:loss_lambda is down to 6.400000000000002e-08
step25:loss_lambda is down to 6.400000000000002e-08
step31:loss_lambda is down to 6.400000000000002e-08
step48:loss_lambda is up to 3.200000000000001e-07
e=2, loss=nan, loss_cos=nan, loss_reg=22235.162280, cur_reg_best=24483.029448, es_reg_best:24483.029448
epoch: 3  lr: 0.5000
step5:loss_lambda is up to 1.6000000000000006e-06
step11:loss_lambda is up to 8.000000000000003e-06
