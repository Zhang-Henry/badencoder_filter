Namespace(arch='resnet18', batch_size=64, encoder_path='/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_200.pth', encoder_usage_info='cifar10', gpu='3', id='_home_hrzhang_model_200.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_200.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
e=0, loss=-0.634912, loss_cos=-0.907953, loss_reg=503.929947, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
step11:loss_lambda is up to 4.000000000000001e-05
e=1, loss=-0.977375, loss_cos=-0.990408, loss_reg=648.297902, cur_reg_best=639.898443, es_reg_best:639.898443
epoch: 2  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
e=2, loss=-0.934175, loss_cos=-0.985034, loss_reg=487.597137, cur_reg_best=508.696597, es_reg_best:508.696597
epoch: 3  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
e=3, loss=-0.941481, loss_cos=-0.985152, loss_reg=434.368237, cur_reg_best=476.321962, es_reg_best:476.321962
epoch: 4  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
step7:loss_lambda is down to 4.000000000000001e-05
step15:loss_lambda is up to 0.00020000000000000004
e=4, loss=-0.943454, loss_cos=-0.985242, loss_reg=417.663502, cur_reg_best=471.642888, es_reg_best:471.642888
epoch: 5  lr: 0.5000
step6:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=5, loss=-0.939798, loss_cos=-0.985697, loss_reg=410.384503, cur_reg_best=465.659189, es_reg_best:465.659189
epoch: 6  lr: 0.5000
step5:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=6, loss=-0.940990, loss_cos=-0.985496, loss_reg=405.708245, cur_reg_best=465.659189, es_reg_best:465.659189
epoch: 7  lr: 0.5000
step4:loss_lambda is down to 4.000000000000001e-05
step12:loss_lambda is up to 0.00020000000000000004
e=7, loss=-0.941792, loss_cos=-0.985073, loss_reg=393.612041, cur_reg_best=443.811993, es_reg_best:443.811993
epoch: 8  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
step10:loss_lambda is up to 0.00020000000000000004
e=8, loss=-0.938645, loss_cos=-0.984822, loss_reg=390.131707, cur_reg_best=418.918903, es_reg_best:418.918903
epoch: 9  lr: 0.5000
step1:loss_lambda is down to 4.000000000000001e-05
step9:loss_lambda is up to 0.00020000000000000004
e=9, loss=-0.942651, loss_cos=-0.985535, loss_reg=393.057768, cur_reg_best=418.918903, es_reg_best:418.918903
epoch: 10  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
step8:loss_lambda is up to 0.00020000000000000004
step15:loss_lambda is down to 4.000000000000001e-05
e=10, loss=-0.943245, loss_cos=-0.985515, loss_reg=391.341626, cur_reg_best=418.918903, es_reg_best:418.918903
epoch: 11  lr: 0.5000
step7:loss_lambda is up to 0.00020000000000000004
step14:loss_lambda is down to 4.000000000000001e-05
e=11, loss=-0.946324, loss_cos=-0.985760, loss_reg=392.049606, cur_reg_best=418.918903, es_reg_best:418.918903
epoch: 12  lr: 0.5000
step6:loss_lambda is up to 0.00020000000000000004
step13:loss_lambda is down to 4.000000000000001e-05
e=12, loss=-0.947122, loss_cos=-0.986250, loss_reg=392.231274, cur_reg_best=418.918903, es_reg_best:418.918903
epoch: 13  lr: 0.5000
step4:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
e=13, loss=-0.946796, loss_cos=-0.986671, loss_reg=401.946542, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 14  lr: 0.5000
step2:loss_lambda is up to 0.00020000000000000004
step9:loss_lambda is down to 4.000000000000001e-05
e=14, loss=-0.946654, loss_cos=-0.987008, loss_reg=405.813908, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 15  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
step15:loss_lambda is up to 0.00020000000000000004
e=15, loss=-0.947333, loss_cos=-0.986975, loss_reg=400.154760, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 16  lr: 0.5000
step6:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=16, loss=-0.942513, loss_cos=-0.986909, loss_reg=398.919706, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 17  lr: 0.5000
step5:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=17, loss=-0.943330, loss_cos=-0.986258, loss_reg=389.197558, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 18  lr: 0.5000
step4:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is up to 0.00020000000000000004
e=18, loss=-0.939781, loss_cos=-0.984735, loss_reg=378.620761, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 19  lr: 0.5000
step2:loss_lambda is down to 4.000000000000001e-05
step10:loss_lambda is up to 0.00020000000000000004
e=19, loss=-0.943759, loss_cos=-0.985943, loss_reg=386.390065, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 20  lr: 0.5000
step1:loss_lambda is down to 4.000000000000001e-05
step9:loss_lambda is up to 0.00020000000000000004
e=20, loss=-0.943739, loss_cos=-0.986051, loss_reg=388.941165, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 21  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
step8:loss_lambda is up to 0.00020000000000000004
step15:loss_lambda is down to 4.000000000000001e-05
e=21, loss=-0.943687, loss_cos=-0.985737, loss_reg=387.265253, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 22  lr: 0.5000
step7:loss_lambda is up to 0.00020000000000000004
step14:loss_lambda is down to 4.000000000000001e-05
e=22, loss=-0.946732, loss_cos=-0.985888, loss_reg=387.601775, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 23  lr: 0.5000
step6:loss_lambda is up to 0.00020000000000000004
step13:loss_lambda is down to 4.000000000000001e-05
e=23, loss=-0.947381, loss_cos=-0.986628, loss_reg=392.192644, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 24  lr: 0.5000
step5:loss_lambda is up to 0.00020000000000000004
step12:loss_lambda is down to 4.000000000000001e-05
e=24, loss=-0.947559, loss_cos=-0.986881, loss_reg=394.219003, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 25  lr: 0.5000
step4:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
e=25, loss=-0.947829, loss_cos=-0.987221, loss_reg=400.492661, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 26  lr: 0.5000
step3:loss_lambda is up to 0.00020000000000000004
step10:loss_lambda is down to 4.000000000000001e-05
e=26, loss=-0.947700, loss_cos=-0.986783, loss_reg=391.595546, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 27  lr: 0.5000
step2:loss_lambda is up to 0.00020000000000000004
step9:loss_lambda is down to 4.000000000000001e-05
e=27, loss=-0.948197, loss_cos=-0.987172, loss_reg=395.980950, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 28  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
step15:loss_lambda is up to 0.00020000000000000004
e=28, loss=-0.947991, loss_cos=-0.987064, loss_reg=393.806546, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 29  lr: 0.5000
step6:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=29, loss=-0.943192, loss_cos=-0.986784, loss_reg=392.903139, cur_reg_best=396.943644, es_reg_best:396.943644
epoch: 30  lr: 0.1000
step5:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=30, loss=-0.947923, loss_cos=-0.986655, loss_reg=363.617671, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 31  lr: 0.1000
step6:loss_lambda is down to 4.000000000000001e-05
e=31, loss=-0.948869, loss_cos=-0.986209, loss_reg=352.808331, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 32  lr: 0.1000
step0:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
e=32, loss=-0.944899, loss_cos=-0.986176, loss_reg=352.556295, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 33  lr: 0.1000
step3:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
e=33, loss=-0.945108, loss_cos=-0.986414, loss_reg=355.130094, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 34  lr: 0.1000
step6:loss_lambda is up to 0.00020000000000000004
step14:loss_lambda is down to 4.000000000000001e-05
e=34, loss=-0.945754, loss_cos=-0.987499, loss_reg=365.872969, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 35  lr: 0.1000
step9:loss_lambda is up to 0.00020000000000000004
e=35, loss=-0.952233, loss_cos=-0.988251, loss_reg=371.286311, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 36  lr: 0.1000
step1:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=36, loss=-0.959307, loss_cos=-0.988243, loss_reg=373.072163, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 37  lr: 0.1000
step4:loss_lambda is down to 4.000000000000001e-05
step14:loss_lambda is up to 0.00020000000000000004
e=37, loss=-0.952397, loss_cos=-0.986766, loss_reg=359.391519, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 38  lr: 0.1000
step6:loss_lambda is down to 4.000000000000001e-05
e=38, loss=-0.949337, loss_cos=-0.986183, loss_reg=350.189333, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 39  lr: 0.1000
step0:loss_lambda is up to 0.00020000000000000004
step7:loss_lambda is down to 4.000000000000001e-05
e=39, loss=-0.948474, loss_cos=-0.986797, loss_reg=356.816900, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 40  lr: 0.1000
step2:loss_lambda is up to 0.00020000000000000004
step10:loss_lambda is down to 4.000000000000001e-05
e=40, loss=-0.945158, loss_cos=-0.986415, loss_reg=353.281755, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 41  lr: 0.1000
step5:loss_lambda is up to 0.00020000000000000004
step13:loss_lambda is down to 4.000000000000001e-05
e=41, loss=-0.945460, loss_cos=-0.987055, loss_reg=361.107241, cur_reg_best=374.383336, es_reg_best:374.383336
epoch: 42  lr: 0.1000
step7:loss_lambda is up to 0.00020000000000000004
step15:loss_lambda is down to 4.000000000000001e-05
e=42, loss=-0.945849, loss_cos=-0.987101, loss_reg=359.956963, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 43  lr: 0.1000
step9:loss_lambda is up to 0.00020000000000000004
e=43, loss=-0.952220, loss_cos=-0.987953, loss_reg=366.183781, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 44  lr: 0.1000
step1:loss_lambda is down to 4.000000000000001e-05
step11:loss_lambda is up to 0.00020000000000000004
e=44, loss=-0.952145, loss_cos=-0.987715, loss_reg=364.537881, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 45  lr: 0.1000
step2:loss_lambda is down to 4.000000000000001e-05
step13:loss_lambda is up to 0.00020000000000000004
e=45, loss=-0.955794, loss_cos=-0.987585, loss_reg=365.149291, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 46  lr: 0.1000
step5:loss_lambda is down to 4.000000000000001e-05
e=46, loss=-0.953405, loss_cos=-0.986282, loss_reg=352.156255, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 47  lr: 0.1000
step0:loss_lambda is up to 0.00020000000000000004
step8:loss_lambda is down to 4.000000000000001e-05
e=47, loss=-0.945081, loss_cos=-0.986238, loss_reg=352.560845, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 48  lr: 0.1000
step3:loss_lambda is up to 0.00020000000000000004
step11:loss_lambda is down to 4.000000000000001e-05
e=48, loss=-0.945163, loss_cos=-0.986342, loss_reg=354.893982, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 49  lr: 0.1000
step5:loss_lambda is up to 0.00020000000000000004
step13:loss_lambda is down to 4.000000000000001e-05
e=49, loss=-0.945372, loss_cos=-0.986797, loss_reg=358.713317, cur_reg_best=374.301855, es_reg_best:374.301855
epoch: 50  lr: 0.0500
step3:loss_lambda is down to 8.000000000000001e-06
step11:loss_lambda is up to 4.000000000000001e-05
e=50, loss=-0.981408, loss_cos=-0.990970, loss_reg=400.720513, cur_reg_best=374.301855, es_reg_best:374.301855
Early stop!
End:106.6024s
L1:374.3019:/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_200.pth:
reg: 503.93,648.3,487.6,434.37,417.66,410.38,405.71,393.61,390.13,393.06,391.34,392.05,392.23,401.95,405.81,400.15,398.92,389.2,378.62,386.39,388.94,387.27,387.6,392.19,394.22,400.49,391.6,395.98,393.81,392.9,363.62,352.81,352.56,355.13,365.87,371.29,373.07,359.39,350.19,356.82,353.28,361.11,359.96,366.18,364.54,365.15,352.16,352.56,354.89,358.71,400.72
cos: 0.91,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.99
