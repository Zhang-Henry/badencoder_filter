Namespace(arch='resnet18', batch_size=64, encoder_path='/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_25.pth', encoder_usage_info='cifar10', gpu='3', id='_home_hrzhang_model_25.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_25.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
step5:loss_lambda is down to 0.0002
step11:loss_lambda is down to 4e-05
e=0, loss=-0.654122, loss_cos=-0.925657, loss_reg=461.220679, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step9:loss_lambda is up to 0.0002
e=1, loss=-0.951581, loss_cos=-0.989278, loss_reg=411.678667, cur_reg_best=403.101278, es_reg_best:403.101278
epoch: 2  lr: 0.5000
step1:loss_lambda is down to 4e-05
step10:loss_lambda is up to 0.0002
e=2, loss=-0.952483, loss_cos=-0.987777, loss_reg=344.323399, cur_reg_best=383.994533, es_reg_best:383.994533
epoch: 3  lr: 0.5000
step1:loss_lambda is down to 4e-05
step8:loss_lambda is up to 0.0002
step15:loss_lambda is down to 4e-05
e=3, loss=-0.949037, loss_cos=-0.988273, loss_reg=322.736482, cur_reg_best=327.118064, es_reg_best:327.118064
epoch: 4  lr: 0.5000
step6:loss_lambda is up to 0.0002
step14:loss_lambda is down to 4e-05
e=4, loss=-0.952881, loss_cos=-0.988553, loss_reg=319.401377, cur_reg_best=321.073873, es_reg_best:321.073873
epoch: 5  lr: 0.5000
step5:loss_lambda is up to 0.0002
step12:loss_lambda is down to 4e-05
e=5, loss=-0.956688, loss_cos=-0.989805, loss_reg=325.769205, cur_reg_best=321.073873, es_reg_best:321.073873
epoch: 6  lr: 0.5000
step3:loss_lambda is up to 0.0002
step10:loss_lambda is down to 4e-05
e=6, loss=-0.957368, loss_cos=-0.990315, loss_reg=328.089840, cur_reg_best=321.073873, es_reg_best:321.073873
Early stop!
End:33.6876s
L1:321.0739:/home/hrzhang/projects/badencoder_filter/output/stl10/svhn_backdoored_encoder/2024-01-04-20:26:54//model_25.pth:
reg: 461.22,411.68,344.32,322.74,319.4,325.77,328.09
cos: 0.93,0.99,0.99,0.99,0.99,0.99,0.99
