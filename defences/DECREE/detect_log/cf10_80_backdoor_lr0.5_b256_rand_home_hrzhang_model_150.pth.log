Namespace(arch='resnet18', batch_size=256, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/svhn_backdoored_encoder/2023-12-20-16:04:09/model_150.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_150.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/svhn_backdoored_encoder/2023-12-20-16:04:09/model_150.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
e=0, loss=-0.052008, loss_cos=-0.907663, loss_reg=855.654964, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 0.0002
e=1, loss=-0.740151, loss_cos=-0.903703, loss_reg=271.338021, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=2, loss=-0.895576, loss_cos=-0.967473, loss_reg=359.486375, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 3  lr: 0.5000
e=3, loss=-0.961137, loss_cos=-0.976866, loss_reg=393.219685, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 4  lr: 0.5000
step1:loss_lambda is down to 8.000000000000001e-06
e=4, loss=-0.974354, loss_cos=-0.985539, loss_reg=475.310675, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 5  lr: 0.5000
e=5, loss=-0.985353, loss_cos=-0.989683, loss_reg=541.317368, cur_reg_best=551.137213, es_reg_best:551.137213
epoch: 6  lr: 0.5000
step3:loss_lambda is up to 4.000000000000001e-05
e=6, loss=-0.987045, loss_cos=-0.991754, loss_reg=588.695760, cur_reg_best=551.137213, es_reg_best:551.137213
epoch: 7  lr: 0.5000
e=7, loss=-0.968802, loss_cos=-0.992211, loss_reg=585.225846, cur_reg_best=551.137213, es_reg_best:551.137213
epoch: 8  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=8, loss=-0.930331, loss_cos=-0.989820, loss_reg=514.961568, cur_reg_best=532.243152, es_reg_best:532.243152
epoch: 9  lr: 0.5000
e=9, loss=-0.904533, loss_cos=-0.974281, loss_reg=348.743882, cur_reg_best=532.243152, es_reg_best:532.243152
epoch: 10  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=10, loss=-0.952351, loss_cos=-0.981065, loss_reg=385.392969, cur_reg_best=532.243152, es_reg_best:532.243152
epoch: 11  lr: 0.5000
e=11, loss=-0.970816, loss_cos=-0.990555, loss_reg=493.462790, cur_reg_best=486.917635, es_reg_best:486.917635
epoch: 12  lr: 0.5000
step2:loss_lambda is up to 0.00020000000000000004
e=12, loss=-0.952409, loss_cos=-0.990702, loss_reg=478.651863, cur_reg_best=477.316388, es_reg_best:477.316388
epoch: 13  lr: 0.5000
e=13, loss=-0.907817, loss_cos=-0.976798, loss_reg=344.905894, cur_reg_best=477.316388, es_reg_best:477.316388
epoch: 14  lr: 0.5000
step1:loss_lambda is down to 4.000000000000001e-05
e=14, loss=-0.939667, loss_cos=-0.978509, loss_reg=344.408644, cur_reg_best=477.316388, es_reg_best:477.316388
epoch: 15  lr: 0.5000
e=15, loss=-0.971807, loss_cos=-0.990908, loss_reg=477.510639, cur_reg_best=468.410600, es_reg_best:468.410600
epoch: 16  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=16, loss=-0.937560, loss_cos=-0.988990, loss_reg=443.508326, cur_reg_best=465.601766, es_reg_best:465.601766
epoch: 17  lr: 0.5000
e=17, loss=-0.911046, loss_cos=-0.975313, loss_reg=321.335603, cur_reg_best=465.601766, es_reg_best:465.601766
epoch: 18  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=18, loss=-0.955521, loss_cos=-0.983168, loss_reg=373.140315, cur_reg_best=465.601766, es_reg_best:465.601766
epoch: 19  lr: 0.5000
e=19, loss=-0.972494, loss_cos=-0.990732, loss_reg=455.941094, cur_reg_best=450.033747, es_reg_best:450.033747
epoch: 20  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=20, loss=-0.939550, loss_cos=-0.988791, loss_reg=424.673525, cur_reg_best=444.390815, es_reg_best:444.390815
epoch: 21  lr: 0.5000
e=21, loss=-0.913755, loss_cos=-0.976768, loss_reg=315.065542, cur_reg_best=444.390815, es_reg_best:444.390815
epoch: 22  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=22, loss=-0.956567, loss_cos=-0.983038, loss_reg=359.954564, cur_reg_best=444.390815, es_reg_best:444.390815
epoch: 23  lr: 0.5000
e=23, loss=-0.973066, loss_cos=-0.990798, loss_reg=443.302884, cur_reg_best=435.784355, es_reg_best:435.784355
epoch: 24  lr: 0.5000
step1:loss_lambda is up to 0.00020000000000000004
e=24, loss=-0.940884, loss_cos=-0.989277, loss_reg=416.514863, cur_reg_best=434.908326, es_reg_best:434.908326
epoch: 25  lr: 0.5000
e=25, loss=-0.915549, loss_cos=-0.977912, loss_reg=311.818656, cur_reg_best=434.908326, es_reg_best:434.908326
epoch: 26  lr: 0.5000
step0:loss_lambda is down to 4.000000000000001e-05
e=26, loss=-0.957802, loss_cos=-0.983972, loss_reg=359.851646, cur_reg_best=434.908326, es_reg_best:434.908326
epoch: 27  lr: 0.5000
e=27, loss=-0.973707, loss_cos=-0.991174, loss_reg=436.669247, cur_reg_best=431.849248, es_reg_best:431.849248
epoch: 28  lr: 0.5000
step0:loss_lambda is up to 0.00020000000000000004
e=28, loss=-0.926991, loss_cos=-0.984605, loss_reg=373.982667, cur_reg_best=426.676822, es_reg_best:426.676822
epoch: 29  lr: 0.5000
step3:loss_lambda is down to 4.000000000000001e-05
e=29, loss=-0.917920, loss_cos=-0.979286, loss_reg=306.828944, cur_reg_best=426.676822, es_reg_best:426.676822
epoch: 30  lr: 0.1000
e=30, loss=-0.969140, loss_cos=-0.981836, loss_reg=317.408259, cur_reg_best=426.676822, es_reg_best:426.676822
epoch: 31  lr: 0.1000
step1:loss_lambda is down to 8.000000000000001e-06
e=31, loss=-0.979663, loss_cos=-0.988664, loss_reg=381.370388, cur_reg_best=426.676822, es_reg_best:426.676822
epoch: 32  lr: 0.1000
e=32, loss=-0.987434, loss_cos=-0.990827, loss_reg=424.034896, cur_reg_best=419.192843, es_reg_best:419.192843
epoch: 33  lr: 0.1000
step2:loss_lambda is up to 4.000000000000001e-05
e=33, loss=-0.984635, loss_cos=-0.992011, loss_reg=456.451091, cur_reg_best=419.192843, es_reg_best:419.192843
epoch: 34  lr: 0.1000
e=34, loss=-0.974104, loss_cos=-0.992156, loss_reg=451.283790, cur_reg_best=419.192843, es_reg_best:419.192843
epoch: 35  lr: 0.1000
step0:loss_lambda is up to 0.00020000000000000004
e=35, loss=-0.926230, loss_cos=-0.990488, loss_reg=408.022328, cur_reg_best=400.403305, es_reg_best:400.403305
epoch: 36  lr: 0.1000
e=36, loss=-0.918618, loss_cos=-0.982020, loss_reg=317.014154, cur_reg_best=400.403305, es_reg_best:400.403305
epoch: 37  lr: 0.1000
step0:loss_lambda is down to 4.000000000000001e-05
e=37, loss=-0.958046, loss_cos=-0.982311, loss_reg=311.130620, cur_reg_best=400.403305, es_reg_best:400.403305
epoch: 38  lr: 0.1000
step2:loss_lambda is down to 8.000000000000001e-06
e=38, loss=-0.977014, loss_cos=-0.988931, loss_reg=375.721731, cur_reg_best=400.403305, es_reg_best:400.403305
epoch: 39  lr: 0.1000
e=39, loss=-0.987849, loss_cos=-0.991180, loss_reg=416.393721, cur_reg_best=399.397005, es_reg_best:399.397005
epoch: 40  lr: 0.1000
step1:loss_lambda is up to 4.000000000000001e-05
e=40, loss=-0.981509, loss_cos=-0.992510, loss_reg=454.487849, cur_reg_best=399.397005, es_reg_best:399.397005
epoch: 41  lr: 0.1000
step3:loss_lambda is up to 0.00020000000000000004
e=41, loss=-0.974777, loss_cos=-0.992362, loss_reg=439.624137, cur_reg_best=399.397005, es_reg_best:399.397005
Early stop!
End:103.5523s
L1:399.3970:/home/hrzhang/projects/badencoder_filter/output/cifar10/svhn_backdoored_encoder/2023-12-20-16:04:09/model_150.pth:
reg: 855.65,271.34,359.49,393.22,475.31,541.32,588.7,585.23,514.96,348.74,385.39,493.46,478.65,344.91,344.41,477.51,443.51,321.34,373.14,455.94,424.67,315.07,359.95,443.3,416.51,311.82,359.85,436.67,373.98,306.83,317.41,381.37,424.03,456.45,451.28,408.02,317.01,311.13,375.72,416.39,454.49,439.62
cos: 0.91,0.9,0.97,0.98,0.99,0.99,0.99,0.99,0.99,0.97,0.98,0.99,0.99,0.98,0.98,0.99,0.99,0.98,0.98,0.99,0.99,0.98,0.98,0.99,0.99,0.98,0.98,0.99,0.98,0.98,0.98,0.99,0.99,0.99,0.99,0.99,0.98,0.98,0.99,0.99,0.99,0.99
