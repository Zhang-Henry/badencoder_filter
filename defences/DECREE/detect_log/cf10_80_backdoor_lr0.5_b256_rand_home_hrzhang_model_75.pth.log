Namespace(arch='resnet18', batch_size=256, encoder_path='/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_75.pth', encoder_usage_info='cifar10', gpu='5', id='_home_hrzhang_model_75.pth', lr=0.5, mask_init='rand', model_flag='backdoor', result_file='resultfinal_filter_txt.txt', seed=80, thres=0.99)
backdoor loaded: /home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_75.pth
trigger: trigger/trigger_pt_white_21_10_ap_replace.npz
mask_size:32
shadow transform: Compose(
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
shadow dataset size: 1000
Config: lambda_min: 1e-05, adapt_lambda: 5.0, lambda_set_patience: 10,succ_threshold: 0.99, early_stop_patience: 10,
epoch: 0  lr: 0.5000
e=0, loss=-0.110218, loss_cos=-0.958131, loss_reg=847.913730, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 1  lr: 0.5000
step1:loss_lambda is down to 0.0002
e=1, loss=-0.841103, loss_cos=-0.952589, loss_reg=173.676295, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 2  lr: 0.5000
step3:loss_lambda is down to 4e-05
e=2, loss=-0.944221, loss_cos=-0.981153, loss_reg=184.658950, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 3  lr: 0.5000
e=3, loss=-0.977882, loss_cos=-0.985826, loss_reg=198.590122, cur_reg_best=10000000.000000, es_reg_best:10000000.000000
epoch: 4  lr: 0.5000
e=4, loss=-0.980802, loss_cos=-0.990297, loss_reg=237.377567, cur_reg_best=236.961429, es_reg_best:236.961429
epoch: 5  lr: 0.5000
step2:loss_lambda is up to 0.0002
e=5, loss=-0.971970, loss_cos=-0.991428, loss_reg=243.178188, cur_reg_best=236.961429, es_reg_best:236.961429
epoch: 6  lr: 0.5000
e=6, loss=-0.949806, loss_cos=-0.985110, loss_reg=176.520880, cur_reg_best=236.961429, es_reg_best:236.961429
epoch: 7  lr: 0.5000
step1:loss_lambda is down to 4e-05
e=7, loss=-0.965980, loss_cos=-0.985858, loss_reg=171.706897, cur_reg_best=236.961429, es_reg_best:236.961429
epoch: 8  lr: 0.5000
e=8, loss=-0.982712, loss_cos=-0.992439, loss_reg=243.160396, cur_reg_best=235.303377, es_reg_best:235.303377
epoch: 9  lr: 0.5000
step1:loss_lambda is up to 0.0002
e=9, loss=-0.966257, loss_cos=-0.991093, loss_reg=219.692607, cur_reg_best=235.303377, es_reg_best:235.303377
epoch: 10  lr: 0.5000
e=10, loss=-0.953592, loss_cos=-0.984919, loss_reg=156.634916, cur_reg_best=235.303377, es_reg_best:235.303377
epoch: 11  lr: 0.5000
step0:loss_lambda is down to 4e-05
e=11, loss=-0.974977, loss_cos=-0.988698, loss_reg=187.664664, cur_reg_best=204.273923, es_reg_best:204.273923
epoch: 12  lr: 0.5000
step3:loss_lambda is up to 0.0002
e=12, loss=-0.983919, loss_cos=-0.993539, loss_reg=240.502209, cur_reg_best=204.273923, es_reg_best:204.273923
epoch: 13  lr: 0.5000
e=13, loss=-0.952702, loss_cos=-0.986828, loss_reg=170.626941, cur_reg_best=204.273923, es_reg_best:204.273923
epoch: 14  lr: 0.5000
step2:loss_lambda is down to 4e-05
e=14, loss=-0.962501, loss_cos=-0.985696, loss_reg=145.476817, cur_reg_best=204.273923, es_reg_best:204.273923
epoch: 15  lr: 0.5000
e=15, loss=-0.983909, loss_cos=-0.993169, loss_reg=231.498917, cur_reg_best=204.273923, es_reg_best:204.273923
Early stop!
End:89.7782s
L1:204.2739:/home/hrzhang/projects/badencoder_filter/output/cifar10/stl10_backdoored_encoder/2023-12-25-20:38:31/model_75.pth:
reg: 847.91,173.68,184.66,198.59,237.38,243.18,176.52,171.71,243.16,219.69,156.63,187.66,240.5,170.63,145.48,231.5
cos: 0.96,0.95,0.98,0.99,0.99,0.99,0.99,0.99,0.99,0.99,0.98,0.99,0.99,0.99,0.99,0.99
