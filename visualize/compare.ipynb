{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(weights='IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from datasets.backdoor_dataset import CIFAR10M,CustomDataset_224,CIFAR10Mem\n",
    "import numpy as np\n",
    "from datasets.bd_dataset_imagenet_filter import BadEncoderDataset\n",
    "\n",
    "\n",
    "def cifar10_dataloader():\n",
    "    batch_size=128\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(32),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "\n",
    "    clean_transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "                ])\n",
    "\n",
    "    memory_data = CIFAR10M(numpy_file='../data/cifar10/train.npz', class_type=classes, transform=train_transform,transform2=clean_transform)\n",
    "    train_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    test_data = CIFAR10M(numpy_file='../data/cifar10/test.npz', class_type=classes, transform=train_transform,transform2=clean_transform)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader,test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datasets.backdoor_dataset import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets.trans import *\n",
    "import argparse\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "class BadEncoderTestBackdoor(Dataset):\n",
    "\n",
    "    def __init__(self, numpy_file, trigger_file, reference_label, aug_transform=None, clean_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            numpy_file (string): Path to the numpy file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.input_array = np.load(numpy_file)\n",
    "        self.data = self.input_array['x']\n",
    "        self.targets = self.input_array['y']\n",
    "\n",
    "\n",
    "        self.trigger_input_array = np.load(trigger_file)\n",
    "\n",
    "        self.trigger_patch_list = self.trigger_input_array['t']\n",
    "        self.trigger_mask_list = self.trigger_input_array['tm']\n",
    "\n",
    "        self.target_class = reference_label\n",
    "\n",
    "        self.test_transform = clean_transform\n",
    "        self.aug_transform = aug_transform\n",
    "\n",
    "        # state_dict = torch.load(trigger_file, map_location=torch.device('cpu'))\n",
    "        # self.net = U_Net_tiny(img_ch=3,output_ch=3)\n",
    "        # self.net.load_state_dict(state_dict['model_state_dict'])\n",
    "        # self.net=self.net.eval()\n",
    "\n",
    "        # self.filter = torch.load('trigger/filter.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img = copy.deepcopy(self.data[index])\n",
    "\n",
    "        ########################\n",
    "        img_ = Image.fromarray(img)\n",
    "        img_clean =self.test_transform(img_)\n",
    "        img_clean_aug = self.aug_transform(img_)\n",
    "\n",
    "        ###########################\n",
    "        ### for ins filter only ###\n",
    "\n",
    "        image_pil = Image.fromarray(img)\n",
    "        filtered_image_pil = pilgram.xpro2(image_pil)\n",
    "        img_backdoor_ins =self.test_transform(filtered_image_pil)\n",
    "        img_backdoor_ins_aug = self.aug_transform(filtered_image_pil)\n",
    "\n",
    "        ###########################\n",
    "\n",
    "        # img[:] =img * self.trigger_mask_list[0] + self.trigger_patch_list[0][:]\n",
    "        # img_backdoor_patch =self.test_transform(Image.fromarray(img))\n",
    "\n",
    "\n",
    "\n",
    "        return img_clean, img_clean_aug, img_backdoor_ins, img_backdoor_ins_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "args=argparse.Namespace(\n",
    "    data_dir='../data/cifar10/',\n",
    "    patch='../trigger/trigger_pt_white_21_10_ap_replace.npz',\n",
    "    filter='../optimize_filter/trigger/cifar10/2023-12-06-23-41-20/ssim0.9328_psnr22.50_lp0.0291_wd0.603_color11.353.pt',\n",
    "    reference_file='reference/cifar10/truck.npz',\n",
    "    reference_label=0,\n",
    "    shadow_dataset='cifar10'\n",
    ")\n",
    "test_data_backdoor = BadEncoderTestBackdoor(numpy_file=args.data_dir+'test.npz', trigger_file=args.patch, reference_label= args.reference_label,  aug_transform=train_transform,clean_transform=test_transform_cifar10)\n",
    "test_data_backdoor=DataLoader(test_data_backdoor, batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "net = U_Net_tiny(img_ch=3,output_ch=3)\n",
    "state_dict = torch.load(args.filter, map_location=torch.device('cuda:0'))\n",
    "net.load_state_dict(state_dict['model_state_dict'])\n",
    "net=net.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from optimize_filter.PyTorch_CIFAR10.cifar10_models.resnet import resnet34\n",
    "from torch.nn import Identity\n",
    "import pickle\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "backbone = resnet34(pretrained=True)\n",
    "backbone.fc = Identity()\n",
    "\n",
    "# 将模型移动到GPU\n",
    "backbone = backbone.to(device)\n",
    "\n",
    "backbone.eval() # for evaluation\n",
    "# 对于每个图像，提取特征\n",
    "features_patch_all = []\n",
    "features_ins_all = []\n",
    "feature_filter_all = []\n",
    "\n",
    "\n",
    "for img_clean, img_clean_aug, img_backdoor_ins, img_backdoor_ins_aug in test_data_backdoor:\n",
    "\n",
    "    # 将数据移动到GPU\n",
    "    img_backdoor_patch = img_backdoor_patch.to(device)\n",
    "    img_backdoor_ins_aug = img_backdoor_ins_aug.to(device)\n",
    "    img_backdoor_ins = img_backdoor_ins.to(device)\n",
    "    img_clean_aug = img_clean_aug.to(device)\n",
    "    img_clean = img_clean.to(device)\n",
    "\n",
    "    img_backdoor_filter=net(img_clean_aug)\n",
    "\n",
    "    # 计算残差\n",
    "    residual_patch = (img_backdoor_patch - img_clean)\n",
    "    residual_ins = (img_backdoor_ins - img_clean)\n",
    "    residual_filter = (img_backdoor_filter - img_clean)\n",
    "    # 确保在没有梯度的情况下执行前向传播以提取特征\n",
    "    with torch.no_grad():\n",
    "        # 使用backbone提取原始特征\n",
    "\n",
    "        # features_patch = backbone(img_backdoor_patch)\n",
    "        # features_ins = backbone(img_backdoor_ins)\n",
    "        # features_filter = backbone(img_backdoor_filter)\n",
    "\n",
    "        # 使用backbone提取残差特征\n",
    "        features_patch = backbone(residual_patch)\n",
    "        features_ins = backbone(residual_ins)\n",
    "        features_filter = backbone(residual_filter)\n",
    "\n",
    "\n",
    "    features_patch_all.append(features_patch)\n",
    "    features_ins_all.append(features_ins)\n",
    "    feature_filter_all.append(features_filter)\n",
    "# 将所有的特征连接成一个完整的张量\n",
    "features_patch_all = torch.cat(features_patch_all, dim=0)\n",
    "features_ins_all = torch.cat(features_ins_all, dim=0)\n",
    "feature_filter_all = torch.cat(feature_filter_all, dim=0)\n",
    "\n",
    "features = {'patch': features_patch_all, 'ins': features_ins_all, 'filter': feature_filter_all}\n",
    "out = 'feature_bank/features_residual.pkl'\n",
    "\n",
    "with open(out, 'wb') as f:\n",
    "    pickle.dump(features, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from optimize_filter.PyTorch_CIFAR10.cifar10_models.resnet import resnet50\n",
    "from torch.nn import Identity\n",
    "import pickle\n",
    "from util import clamp_batch_images\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "backbone = resnet50(pretrained=True)\n",
    "backbone.fc = Identity()\n",
    "\n",
    "# 将模型移动到GPU\n",
    "backbone = backbone.to(device)\n",
    "\n",
    "backbone.eval() # for evaluation\n",
    "# 对于每个图像，提取特征\n",
    "features_patch_all = []\n",
    "features_ins_all = []\n",
    "features_ins_aug_all = []\n",
    "features_filter_all = []\n",
    "features_filter_aug_all = []\n",
    "\n",
    "\n",
    "for img_clean, img_clean_aug, img_backdoor_ins, img_backdoor_ins_aug in test_data_backdoor:\n",
    "\n",
    "    # 将数据移动到GPU\n",
    "    # img_backdoor_patch = img_backdoor_patch.to(device)\n",
    "    img_backdoor_ins_aug = img_backdoor_ins_aug.to(device)\n",
    "    img_backdoor_ins = img_backdoor_ins.to(device)\n",
    "\n",
    "    img_clean_aug = img_clean_aug.to(device)\n",
    "    img_clean = img_clean.to(device)\n",
    "\n",
    "    img_backdoor_filter=net(img_clean)\n",
    "    img_backdoor_filter=clamp_batch_images(img_backdoor_filter,args)\n",
    "    img_backdoor_filter_aug=net(img_clean_aug)\n",
    "    img_backdoor_filter_aug=clamp_batch_images(img_backdoor_filter_aug,args)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_backdoor_ins = (img_backdoor_ins - img_clean)\n",
    "        img_backdoor_ins_aug = (img_backdoor_ins_aug - img_clean)\n",
    "        img_backdoor_filter = (img_backdoor_filter - img_clean)\n",
    "        img_backdoor_filter_aug = (img_backdoor_filter_aug - img_clean)\n",
    "\n",
    "        # 使用backbone提取残差特征\n",
    "        features_ins = backbone(img_backdoor_ins)\n",
    "        features_ins_aug = backbone(img_backdoor_ins_aug)\n",
    "        features_filter = backbone(img_backdoor_filter)\n",
    "        features_filter_aug = backbone(img_backdoor_filter_aug)\n",
    "\n",
    "\n",
    "    features_ins_aug_all.append(features_ins_aug)\n",
    "    features_ins_all.append(features_ins)\n",
    "    features_filter_all.append(features_filter)\n",
    "    features_filter_aug_all.append(features_filter_aug)\n",
    "\n",
    "# 将所有的特征连接成一个完整的张量\n",
    "features_ins_aug_all = torch.cat(features_ins_aug_all, dim=0)\n",
    "features_ins_all = torch.cat(features_ins_all, dim=0)\n",
    "features_filter_all = torch.cat(features_filter_all, dim=0)\n",
    "features_filter_aug_all = torch.cat(features_filter_aug_all, dim=0)\n",
    "\n",
    "features = {'ins': features_ins_all, 'filter': features_filter_all, 'ins_aug': features_ins_aug_all, 'filter_aug': features_filter_aug_all}\n",
    "out = 'feature_bank/features_residual_aug.pkl'\n",
    "\n",
    "with open(out, 'wb') as f:\n",
    "    pickle.dump(features, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badencoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
